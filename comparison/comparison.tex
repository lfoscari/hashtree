\documentclass[a4paper]{article}

\usepackage{pgfplots}
\pgfplotsset{compat=1.17}

\usepackage[margin=1in]{geometry}

\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage[boxed]{algorithm2e}

% \setlength{\parindent}{0pt}
% \setlength{\parskip}{10pt}

\title{Analisi dell'HH-tree}
\author{Luigi Foscari}
\date{}

\begin{document}

\maketitle

\section{Parametri e metriche}
I parametri della struttura dati sono
\begin{itemize}
	\item $m$ la dimensione massima delle foglie.
	\item $b$ la taglia delle tabelle di hash nei nodi.
	\item $n$ il numero di elementi inseriti (spesso sconosciuto a priori).
\end{itemize}
Le metriche analizzate sono
\begin{itemize}
	\item \textit{Usage} o utilizzo è la percentuale $\in [0, 1]$ di riempimento delle foglie rispetto ad $m$.
	\item \textit{Depth} è la profondità $\in \mathbb{N}$ dell'albero.
\end{itemize}

\section{Relazione tra i parametri e le metriche}

Le seguenti analisi hanno mostrano come gli unici valori \textit{sensati} per $m$ e $b$ sono quelli minori di $n$ e che conviene allontanarsi da valori troppo bassi per entrambi.

È necessario distinguere due implementazioni, nella prima, chiamata \textit{rigida}, il parametro $m$ rimane inalterato in tutta la struttura, nella seconda, chiamata \textit{adattiva}, $m$ è incrementato di 1 per ogni figlio, quindi una foglia a prodondità $t$ avrà una lunghezza massima $m + t$.

% La soluzione migliore per b e m è log2(n)?

\subsection{Implementazione rigida}

L'implementazione in question presenta una condizione sui parametri, nel caso in cui $b = 1$ e $m < n$ è invevitable una ricorsione infinita alla prima scissione, perchè non è possibile inserire tutti gli elementi in un solo bucket, ma non è neanche possibile utilizzare più di un bucket. Perciò $b > 1$ o, meno efficientemente, $m \geq n$.

\begin{itemize}
	\item Riguardo a $b$ possiamo dire che
	\begin{itemize}
		\item Se $b = 2$ l'albero è binario, considerando che l'hashing è universale il valore atteso di utilizzo delle foglie è $1/2$, la profondità è
			$$ \log_2 \left( \frac{m}{2} + 1 \right) - 1. $$
		\item Se $b \geq n$ in valore atteso la profondità è 1 e l'utilizzo è $n / b$.
	\end{itemize}
	\item Riguardo ad $m$ possiamo dire che
	\begin{itemize}
		\item Se $m = 1$ ogni foglia contiene al massimo un elemento, quindi in valore atteso l'utilizzo è $1 / b$ e la profondità è al massimo $n$.
		\item Se $m = n$ l'utilizzo è sempre uguale a $m / b$, mentre la profondità è sempre 1.
	\end{itemize}
\end{itemize}

\subsection{Implementazione adattiva}

\begin{itemize}
	\item Riguardo a $b$ possiamo dire che
	\begin{itemize}
		\item Se $b = 1$ l'utilizzo è sempre 1, perchè c'è una scissione ad ogni inserimento dopo l'$m$-esimo, mentre la profondità è $n - m + 1$.
		\item Se $b = n$ l'utilizzo ha un valore atteso pari a $n/m$ e la profondità $1$, ipotizzando che l'hashing utilizzato sia universale.
	\end{itemize}
	\item Riguardo ad $m$ possiamo dire che
	\begin{itemize}
		\item Al crescere di $m$ da 1 ad $n$ la profondità e l'utilizzo tendono a scendere. 
		\item Dal momento in cui $m = n$ non avvengono scissioni, perciò la profondità sarà sempre 1 e l'utilizzo al 100\%.
	\end{itemize}
\end{itemize}

\section{Valutazione struttura dati}
Le seguenti valutazioni valgono per l'implementazione rigida. Consideriamo inoltre $n > m$, per cui la radice è sempre un nodo e ha $b$ figli.

Consideriamo una struttura dati con solo $n = m + 1$ elementi quindi è presente solo la radice e $b$ foglie. Una foglia è scissa, e quindi diventa nodo, se contiene più di $m$ elementi. La probabilità che in un inserimento una foglia venga scelta rispetto ai suoi fratelli è $1/b$, quindi il numero di scissioni è descritto bene da una variabile aleatoria binomiale $X \sim B(1/b, n)$. Abbiamo che
$$ E[X] = \frac{n}{b} $$
Generalizzando se consideriamo un nodo e le sue $b$ foglie vuote, dopo i primi $n$ inserimenti c'è da aspettarsi di avere effettuato $n/b$ scissioni.

Per la radice questo vale senza eccezioni, però per un nodo a profondità maggiore $n$ è diverso, perchè bisogna considerare solo i valori che effettivamente lo raggiungono. In particolare un nodo a profondità $l$ ha probabilità $1/b^l$ di essere selezionato, rispetto a tutti i nodi al suo livello e a quelli sopra. Quindi in generale al livello $l$ dopo $n$ inserimento bisogna aspettarsi $n/b^l$ scissioni, chiamiamo queste variabili aleatorie $X_l$.

Se definiamo $S$ la variabile aleatorie che descrive il numero di scissioni in base a $b$, il numero totale di scissioni dopo $n$ inserimenti è
$$ E[S] = \sum_{l=0}^{\infty} E[X_l] = \sum_{l=0}^{\infty} \frac{n}{b^l} = n \sum_{l=0}^{\infty} \left(\frac{1}{b}\right)^l = \frac{n}{1 - 1/b}$$
Ma questo non ha senso perchè al crescere di $n$ il numero di scissioni dovrebbe calare. C'è un errore. Ad esempio per $b=2$ devo aspettarmi $2n$ scissioni per ogni $n$ elementi inseriti, che non ha senso.

Proviamo a non usare la binomiale, ma l'ipergeometrica, dopo $n$ inserimento voglio che almeno $m$ siano stati effettuati in una foglia precisa, e questo avviene con probabilità $1/b$, quindi $X \sim H(b, 1, n)$. Questa rappresentazione è analoga perchè $E[X] = n/b$.

% Proviamo ad usare una variabile aleatoria $X$ di Poisson in modo un po' strano, l'intervallo considerato è $1, \dots, n$, la probabilità con cui una foglia è scelta è $\lambda = 1/b$. Abbiamo che $E[X] = 1/b$.

% Valutiamo ora il valore atteso della profondità e dell'utilizzo in base ai parametri $n$, $m$ e $b$ TODO.

% Consideriamo i vari livelli di profondità dell'albero $i \in \mathbb{N}^0$, il numero di elementi massimo per ogni livello $i$ è $mb^i$.
% Chiamaiamo $P_l$ la probabilità che un elemento generico, durante un inserimento, arrivi a profondità almeno $l$, abbiamo che
% $$ P_l = \prod_{i=0}^{l} \frac{n}{mb^i} $$
% Poichè ogni nodo ha $b^i$ figli e c'è una probabilità uniforme che ognuno venga scelto. ???
% Quando $n = m$ abbiamo che $P_0 = 1$.

.

% Sappiamo che un albero di profondità $t$ ha conterrò al massimo $b^tm$ elementi, quindi $n \leq b^tm$ in ogni momento.
% $$ \prod_{i=0}^{l} \frac{n}{mb^i} \leq \prod_{i=0}^{l} \frac{mb^t}{mb^i} = \prod_{i=0}^{l} \frac{b^t}{b^i} = \prod_{i=0}^{l} b^{t - i} = \prod_{i=t - l}^{t} b^i = b^{\sum_{i=t - l}^{t}i} = b^{t - \sum_{i=0}^{l}i} = b^{t - l(l + 1)/2} $$

% \paragraph{Foglia di profondità \boldmath{$p$}}
% 	\begin{itemize}
% 		\item La probabilità che una foglia precisa sia scelta per un inserimento tra i figli del nodo padre è $1/b$, quindi la probabilità di scissione per una foglia generica è $(1/b)^m$ per la probabilità che il nodo padre sia scelto.
% 		\item La probabilità che ci sia una scissione in una foglia è pari alla probabilità che $m$ elementi siano stati aggiunti alla foglia $b^{-p-m}$.
% 	\end{itemize}
% \paragraph{Nodo di profondità \boldmath{$p$}} La probabilità che un elemento $x$ venga inserito in questo nodo è $(1/b)^p$, la probabilità che successivamente sia scelta una foglia è $1 - b^{-m}$ (la probabilità che la foglia non sia ancora stata scissa), invece è $b^{-m}$ la probabilità che sia un nodo.

% \paragraph{Tempi di accesso}
% Il tempo di inserimento di un elemento $x$ fino ad una profondità $p$ è $O(p + b^{-p-m})$. La probabilità che il figlio di un nodo sia una foglia è $1 - b^{-m}$, quindi la probabilità che un elemento $x$ arrivi ad una profondità $p$, che è pari alla probabilità di non aver incontrato neanche un nodo che è stato scisso dalla radice a $p$, è $1/b^{-p-m} = b^{p+m}$ (valore atteso di geometrica di ragione $b^{-m}$).

\section{Strutture dati analoghe}

Un HH-tree con $k$ mappe di feature su un universo $\mathcal{X}$ permette di fare ricerca su più campi, espressi come feature degli elementi di $\mathcal{X}$. Vediamo ora due strutture dati naïve che permettono di effettuare le stesse operazioni. Assumiamo sempre di avere a disposizione le mappe di feature per estrarre i valori per le ricerche.

\subsection{Forma lineare}

Gli elementi inseriti $S \subseteq \mathcal{X}$ sono conservati in una lista $A$. La ricerca, come la cancellazione, è effettuata elemento per elemento, calcolando i valori necessari per verificare se l'elemento è quello che si cerca e richiede tempo $O(|S|)$. L'inserimento è costante $O(1)$. Non c'è una grande differenza tra la ricerca su una singola chiave o su molteplici.

\subsection{Tabelle di hash}

Gli elementi inseriti $S \subseteq \mathcal{X}$ sono conservati in un array $A$ e sono create $k$ tabelle di hash di taglia $b$ con bucket, ad ognuna è associata una delle mappe.
\begin{itemize}
	\item L'inserimento di un valore $x \in \mathcal{X}$ è effettuato aggiungendo all'array $x$ e per ognuna delle tabelle di hash calcolare la posizione di $x$ e inserire nella lista di collisione la posizione di $x$ all'interno dell'array.
	\item La ricerca su un insieme di chiavi è definita nel seguente algoritmo
	\begin{algorithm}
		\DontPrintSemicolon \;

		\KwData{$A$ insieme degli elementi, $C$ chiavi, $T$ tabelle}
		\KwOut{Risultato della ricerca su $c$ chiavi}

		Sia $R$ una copia di $A$ \;
		\For{$i = 1, \dots, |T|$} {
			\For{$j = 1, \dots, |C|$} {
				Rimuovi da $R$ ogni elemento che non compare in $T[i][j]$ \;
			}
		}

		\Return $R$ \; \;
	\end{algorithm}
	\item La cancellazione di effettua rimuovendo l'indice dell'elemento da ogni tabella di hash e l'elemento da $A$.
\end{itemize}

Quindi l'inserimento è lineare su $k$, mentre la ricerca con un insieme di chiavi $C$ è $O(|T||C| + n) = O(|T|k + n)$\footnote{$|C| \leq k$}. Lo spazio occupato è invece $O(n + |T|n)$. Inoltre l'inserimento occupa spazio $O(n)$.

% \pagebreak

% \section{\texttt{MAGIC Gamma Telescope Dataset}}

% È stato utilizzato un subset di $n = 50$ righe del \texttt{MAGIC Gamma Telescope Dataset}. Per valori di $m$ e $b$ tra 1 e $n$ sono stati calcolati utilizzo e profondità medi su 10 permutazioni. Questi sono i risultati.

% \begin{center}
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Usage}, zmin=0.0, zmax=1.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=avg_usage, col sep=comma] {../resources/magic/magic04.out};
% 		\end{axis}
% 	\end{tikzpicture}%
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Usage}, zmin=0.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=std_usage, col sep=comma] {../resources/magic/magic04.out};
% 		\end{axis}
% 	\end{tikzpicture}

% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Depth}, zmin=1, zmax=50, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=avg_depth, col sep=comma] {../resources/magic/magic04.out};
% 		\end{axis}
% 	\end{tikzpicture}%
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Depth}, zmin=0.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=std_depth, col sep=comma] {../resources/magic/magic04.out};
% 		\end{axis}
% 	\end{tikzpicture}

% 	\begin{tikzpicture}
% 		\begin{axis}[
% 			xlabel={$m$}, xmin=1, xmax=50,
% 			ylabel={$b$}, ymin=1, ymax=50,
% 			zlabel={Number of accesses}, zmin=0.0, zmajorgrids=true,
% 			width=\textwidth * 0.8
% 		]
% 		\addplot3 [scatter, only marks, mark=+]
% 			table [x=m, y=b, z=avg_access, col sep=comma] {../resources/magic/magic04.out};
% 		\end{axis}
% 	\end{tikzpicture}
% \end{center}

% \pagebreak

% \section{\texttt{Cloud DataSet}}

% È stato utilizzato un subset di $n = 50$ righe del \texttt{Cloud DataSet}. Per valori di $m$ e $b$ tra 1 e $n$ sono stati calcolati utilizzo e profondità medi su 10 permutazioni. Questi sono i risultati.

% \begin{center}
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Usage}, zmin=0.0, zmax=1.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=avg_usage, col sep=comma] {../resources/cloud/cloud.out};
% 		\end{axis}
% 	\end{tikzpicture}%
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Usage}, zmin=0.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=std_usage, col sep=comma] {../resources/cloud/cloud.out};
% 		\end{axis}
% 	\end{tikzpicture}

% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Depth}, zmin=1, zmax=50, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=avg_depth, col sep=comma] {../resources/cloud/cloud.out};
% 		\end{axis}
% 	\end{tikzpicture}%
% 	\begin{tikzpicture}
% 		\begin{axis}[
% 				xlabel={$m$}, xmin=1, xmax=50,
% 				ylabel={$b$}, ymin=1, ymax=50,
% 				zlabel={Depth}, zmin=0.0, zmajorgrids=true,
% 				width=\textwidth * 0.5
% 			]
% 			\addplot3 [scatter, only marks, mark=+]
% 				table [x=m, y=b, z=std_depth, col sep=comma] {../resources/cloud/cloud.out};
% 		\end{axis}
% 	\end{tikzpicture}

% 	\begin{tikzpicture}
% 		\begin{axis}[
% 			xlabel={$m$}, xmin=1, xmax=50,
% 			ylabel={$b$}, ymin=1, ymax=50,
% 			zlabel={Number of accesses}, zmin=0.0, zmajorgrids=true,
% 			width=\textwidth * 0.8
% 		]
% 		\addplot3 [scatter, only marks, mark=+]
% 			table [x=m, y=b, z=avg_access, col sep=comma] {../resources/cloud/cloud.out};
% 		\end{axis}
% 	\end{tikzpicture}
% \end{center}

% \pagebreak

\end{document}